{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OpenCV Edge Detection Script"
      ],
      "metadata": {
        "id": "TKnRGJp7IL85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up and imports"
      ],
      "metadata": {
        "id": "e1c38K1AWVag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5k2rxxFRVqk"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/acarcher/hed-opencv-dl.git"
      ],
      "metadata": {
        "id": "g8cIhYJ3Rd4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "i2WJOjjaRpPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os, shutil\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "MJq3GU3qRfiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crop Layer"
      ],
      "metadata": {
        "id": "9PDUxpiGWePA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CropLayer(object):\n",
        "    def __init__(self, params, blobs):\n",
        "        # initialize our starting and ending (x, y)-coordinates of the crop\n",
        "        self.startX = 0\n",
        "        self.startY = 0\n",
        "        self.endX = 0\n",
        "        self.endY = 0\n",
        "\n",
        "    def getMemoryShapes(self, inputs):\n",
        "        # the crop layer will receive two inputs -- we need to crop\n",
        "        # the first input blob to match the shape of the second one,\n",
        "        # keeping the batch size and number of channels\n",
        "        (inputShape, targetShape) = (inputs[0], inputs[1])\n",
        "        (batchSize, numChannels) = (inputShape[0], inputShape[1])\n",
        "        (H, W) = (targetShape[2], targetShape[3])\n",
        "\n",
        "        # compute the starting and ending crop coordinates\n",
        "        self.startX = int((inputShape[3] - targetShape[3]) / 2)\n",
        "        self.startY = int((inputShape[2] - targetShape[2]) / 2)\n",
        "        self.endX = self.startX + W\n",
        "        self.endY = self.startY + H\n",
        "\n",
        "        # return the shape of the volume (we'll perform the actual\n",
        "        # crop during the forward pass)\n",
        "        return [[batchSize, numChannels, H, W]]\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # use the derviced (x, y)-coordinates to perform the crop\n",
        "        return [inputs[0][:, :, self.startY:self.endY,\n",
        "                                self.startX:self.endX]]"
      ],
      "metadata": {
        "id": "Hrc03K_1Rh1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets \n",
        "In case there are any other dataset in your directory, you can add it to the list, and the script will add the \".npy\" output to the folder.\n",
        "\n",
        "We recommend copying your datasets into a new folder and then run this script as it will add the \".npy\" files into the same directory."
      ],
      "metadata": {
        "id": "f06PbHK0XeXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = ['Kvasir Seg', 'ETIS-LaribPolypDB', 'CVC-ColonDB']"
      ],
      "metadata": {
        "id": "cftOsiniRuqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating edges and creating the 4th layer"
      ],
      "metadata": {
        "id": "-Mfcai4SaKTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading weights and the model\n",
        "net = cv2.dnn.readNetFromCaffe(\"/content/hed-opencv-dl/hed_model/deploy.prototxt\", \"/content/hed-opencv-dl/hed_model/hed_pretrained_bsds.caffemodel\")\n",
        "cv2.dnn_registerLayer(\"Crop\", CropLayer)\n",
        "\n",
        "for dataset in datasets:\n",
        "  train_path = '/content/drive/MyDrive/CSC490 Datasets/FINAL_COMBINED_DATASET_EDGES/Training dataset/{}/images/'.format(dataset)\n",
        "  test_path = '/content/drive/MyDrive/CSC490 Datasets/FINAL_COMBINED_DATASET_EDGES/Test dataset/{}/images/'.format(dataset)\n",
        "\n",
        "  train_images = list(os.listdir(train_path))\n",
        "  test_images = list(os.listdir(test_path))\n",
        "\n",
        "  # setting up train images\n",
        "  for train_image_name in train_images:\n",
        "    if (\".npy\" in train_image_name or train_image_name[:-3] + 'npy' in train_images):\n",
        "      continue\n",
        "    src_path = os.path.join(train_path, train_image_name)\n",
        "    img = cv2.imread(src_path)\n",
        "    (H, W) = img.shape[:2]\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    canny = cv2.Canny(blurred, 30, 150)\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(img, scalefactor=1.0, size=(W, H),\n",
        "                                mean=(104.00698794, 116.66876762, 122.67891434),\n",
        "                                swapRB=False, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "    hed = net.forward()\n",
        "    hed = cv2.resize(hed[0, 0], (W, H))\n",
        "    hed = (255 * hed).astype(\"uint8\")\n",
        "\n",
        "    hed = hed.reshape(hed.shape[0], hed.shape[1], 1)\n",
        "    fourth_layer = np.concatenate((img, hed), axis=2)\n",
        "\n",
        "    np.save(src_path[:-3] + 'npy', fourth_layer)\n",
        "\n",
        "    print(src_path)\n",
        "    \n",
        "\n",
        "  # setting up for test images\n",
        "  for test_image_name in test_images:\n",
        "    src_path = os.path.join(test_path, test_image_name)\n",
        "    img = cv2.imread(src_path)\n",
        "    (H, W) = img.shape[:2]\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    canny = cv2.Canny(blurred, 30, 150)\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(img, scalefactor=1.0, size=(W, H),\n",
        "                                mean=(104.00698794, 116.66876762, 122.67891434),\n",
        "                                swapRB=False, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "    hed = net.forward()\n",
        "    hed = cv2.resize(hed[0, 0], (W, H))\n",
        "    hed = (255 * hed).astype(\"uint8\")\n",
        "\n",
        "    hed = hed.reshape(hed.shape[0], hed.shape[1], 1)\n",
        "    fourth_layer = np.concatenate((img, hed), axis=2)\n",
        "\n",
        "    np.save(src_path[:-3] + 'npy', fourth_layer)\n"
      ],
      "metadata": {
        "id": "JrTuMiUdRlWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing the \".jpg\" files\n",
        "\n",
        "If you want to just have the \".npy\" files in the folder, you can run the script below to achieve this result. "
      ],
      "metadata": {
        "id": "kWQgJeRvZz1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in datasets:\n",
        "  train_path = '/content/drive/MyDrive/CSC490 Datasets/FINAL_COMBINED_DATASET_EDGES/Training dataset/{}/images/'.format(dataset)\n",
        "  test_path = '/content/drive/MyDrive/CSC490 Datasets/FINAL_COMBINED_DATASET_EDGES/Test dataset/{}/images/'.format(dataset)\n",
        "\n",
        "  train_images = list(os.listdir(train_path))\n",
        "  test_images = list(os.listdir(test_path))\n",
        "\n",
        "  # deleting jpgs from train data\n",
        "  for train_image_name in train_images:\n",
        "    if (train_image_name[-3:] == \"jpg\"):\n",
        "      src_path = os.path.join(train_path, train_image_name)\n",
        "      os.remove(src_path)\n",
        "\n",
        "  # deleting jpgs from test data\n",
        "  for test_image_name in test_images:\n",
        "    if (test_image_name[-3:] == \"jpg\"):\n",
        "      src_path = os.path.join(test_path, test_image_name)\n",
        "      os.remove(src_path)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "1fVyEOfUl5wQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}